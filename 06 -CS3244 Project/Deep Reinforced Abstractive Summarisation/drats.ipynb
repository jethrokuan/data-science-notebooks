{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nltk\n",
    "import torchtext\n",
    "from torchtext.data import Example, Field, BucketIterator, TabularDataset\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook, trange\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 29.9 GB  | Proc size: 162.7 MB\n",
      "GPU RAM Free: 12206MB | Used: 0MB | Util   0% | Total 12206MB\n",
      "Mon Mar 26 17:22:42 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   40C    P0    60W / 250W |      0MiB / 12206MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/diskA/jethro/cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.feather',\n",
       " 'train.pkl',\n",
       " 'raw',\n",
       " 'train.tsv',\n",
       " 'stories.feather',\n",
       " 'test.tsv',\n",
       " 'train.feather']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=nltk.word_tokenize,use_vocab=True,lower=True, include_lengths=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=nltk.word_tokenize,use_vocab=True,lower=True, include_lengths=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(path=f'{PATH}/train.tsv',\n",
    "                            format='tsv',\n",
    "                            fields=[('story',TEXT), ('summary',TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(path=f'{PATH}/test.tsv',\n",
    "                            format='tsv',\n",
    "                            fields=[('story',TEXT), ('summary',TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 73975\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, test_data, min_freq=2)\n",
    "\n",
    "tqdm.write(\"Vocabulary size: {}\".format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = BucketIterator(train_data, \n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              device=None,\n",
    "                              sort_key=lambda x: len(x.story),\n",
    "                              sort_within_batch=True,\n",
    "                              repeat=False,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = 100\n",
    "EMBED = 50\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(VOCAB_SIZE,EMBED,HIDDEN,bidirec=True)\n",
    "decoder = Decoder(VOCAB_SIZE,EMBED,HIDDEN*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/740 [00:17<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    tqdm.write(\"Using CUDA\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using %d devices\" % (torch.cuda.device_count()))\n",
    "        encoder = nn.DataParallel(encoder)\n",
    "        decoder = nn.DataParallel(decoder)\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "decoder.embedding = encoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
    "enc_optim = optim.Adam(encoder.parameters(),lr=LR)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:   0%|          | 0/740 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 0:   0%|          | 1/740 [00:00<02:27,  5.02batch/s]\u001b[A\n",
      "Epoch 0:   1%|          | 4/740 [00:00<00:55, 13.31batch/s]\u001b[A\n",
      "Epoch 0:   1%|          | 7/740 [00:00<00:42, 17.27batch/s]\u001b[A\n",
      "Epoch 0:   1%|▏         | 10/740 [00:00<00:37, 19.64batch/s]\u001b[A\n",
      "Epoch 0:   2%|▏         | 13/740 [00:00<00:34, 21.27batch/s]\u001b[A\n",
      "Epoch 0:   2%|▏         | 16/740 [00:00<00:32, 22.43batch/s]\u001b[A\n",
      "Epoch 0:   3%|▎         | 19/740 [00:00<00:30, 23.30batch/s]\u001b[A\n",
      "Epoch 0:   3%|▎         | 22/740 [00:00<00:29, 23.95batch/s]\u001b[A\n",
      "Epoch 0:   3%|▎         | 25/740 [00:01<00:29, 24.49batch/s]\u001b[A\n",
      "Epoch 0:   4%|▍         | 28/740 [00:01<00:28, 24.95batch/s]\u001b[A\n",
      "Epoch 0:   4%|▍         | 31/740 [00:01<00:28, 25.29batch/s]\u001b[A\n",
      "Epoch 0:   5%|▍         | 34/740 [00:01<00:27, 25.61batch/s]\u001b[A\n",
      "Epoch 0:   5%|▌         | 37/740 [00:01<00:27, 25.88batch/s]\u001b[A\n",
      "Epoch 0:   5%|▌         | 40/740 [00:01<00:26, 26.10batch/s]\u001b[A\n",
      "Epoch 0:   6%|▌         | 43/740 [00:01<00:26, 26.31batch/s]\u001b[A\n",
      "Epoch 0:   6%|▌         | 46/740 [00:01<00:26, 26.50batch/s]\u001b[A\n",
      "Epoch 0:   7%|▋         | 49/740 [00:01<00:25, 26.66batch/s]\u001b[A\n",
      "Epoch 0:   7%|▋         | 52/740 [00:01<00:25, 26.81batch/s]\u001b[A\n",
      "Epoch 0:   7%|▋         | 55/740 [00:02<00:25, 26.93batch/s]\u001b[A\n",
      "Epoch 0:   8%|▊         | 58/740 [00:02<00:25, 27.04batch/s]\u001b[A\n",
      "Epoch 0:   8%|▊         | 61/740 [00:02<00:25, 27.14batch/s]\u001b[A\n",
      "Epoch 0:   9%|▊         | 64/740 [00:02<00:24, 27.25batch/s]\u001b[A\n",
      "Epoch 0:   9%|▉         | 67/740 [00:02<00:24, 27.34batch/s]\u001b[A\n",
      "Epoch 0:   9%|▉         | 70/740 [00:02<00:24, 27.42batch/s]\u001b[A\n",
      "Epoch 0:  10%|▉         | 73/740 [00:02<00:24, 27.50batch/s]\u001b[A\n",
      "Epoch 0:  10%|█         | 76/740 [00:02<00:24, 27.56batch/s]\u001b[A\n",
      "Epoch 0:  11%|█         | 79/740 [00:02<00:23, 27.63batch/s]\u001b[A\n",
      "\n",
      "Epoch 0:  11%|█         | 82/740 [00:02<00:23, 27.69batch/s]\u001b[A\n",
      "Epoch 0:  11%|█▏        | 85/740 [00:03<00:23, 27.74batch/s]\u001b[A\n",
      "Epoch 0:  12%|█▏        | 88/740 [00:03<00:23, 27.79batch/s]\u001b[A\n",
      "Epoch 0:  12%|█▏        | 91/740 [00:03<00:23, 27.84batch/s]\u001b[A\n",
      "Epoch 0:  13%|█▎        | 94/740 [00:03<00:23, 27.87batch/s]\u001b[A\n",
      "Epoch 0:  13%|█▎        | 97/740 [00:03<00:23, 27.92batch/s]\u001b[A\n",
      "Epoch 0:  14%|█▎        | 100/740 [00:03<00:22, 27.96batch/s]\u001b[A\n",
      "Epoch 0:  14%|█▍        | 103/740 [00:03<00:22, 28.00batch/s]\u001b[A\n",
      "Epoch 0:  14%|█▍        | 106/740 [00:03<00:23, 27.20batch/s]\u001b[A\n",
      "Epoch 0:  15%|█▍        | 109/740 [00:04<00:23, 27.25batch/s]\u001b[A\n",
      "Epoch 0:  15%|█▌        | 112/740 [00:04<00:23, 27.30batch/s]\u001b[A\n",
      "Epoch 0:  16%|█▌        | 115/740 [00:04<00:22, 27.34batch/s]\u001b[A\n",
      "Epoch 0:  16%|█▌        | 118/740 [00:04<00:22, 27.39batch/s]\u001b[A\n",
      "Epoch 0:  16%|█▋        | 121/740 [00:04<00:22, 27.43batch/s]\u001b[A\n",
      "Epoch 0:  17%|█▋        | 124/740 [00:04<00:22, 27.48batch/s]\u001b[A\n",
      "Epoch 0:  17%|█▋        | 127/740 [00:04<00:22, 27.52batch/s]\u001b[A\n",
      "Epoch 0:  18%|█▊        | 130/740 [00:04<00:22, 27.56batch/s]\u001b[A\n",
      "Epoch 0:  18%|█▊        | 133/740 [00:04<00:21, 27.61batch/s]\u001b[A\n",
      "Epoch 0:  18%|█▊        | 136/740 [00:04<00:21, 27.64batch/s]\u001b[A\n",
      "Epoch 0:  19%|█▉        | 139/740 [00:05<00:21, 27.67batch/s]\u001b[A\n",
      "Epoch 0:  19%|█▉        | 142/740 [00:05<00:21, 27.71batch/s]\u001b[A\n",
      "Epoch 0:  20%|█▉        | 145/740 [00:05<00:21, 27.73batch/s]\u001b[A\n",
      "Epoch 0:  20%|██        | 148/740 [00:05<00:21, 27.76batch/s]\u001b[A\n",
      "Epoch 0:  20%|██        | 151/740 [00:05<00:21, 27.79batch/s]\u001b[A\n",
      "Epoch 0:  21%|██        | 154/740 [00:05<00:21, 27.82batch/s]\u001b[A\n",
      "Epoch 0:  21%|██        | 157/740 [00:05<00:20, 27.84batch/s]\u001b[A\n",
      "Epoch 0:  22%|██▏       | 160/740 [00:05<00:20, 27.87batch/s]\u001b[A\n",
      "Epoch 0:  22%|██▏       | 163/740 [00:05<00:20, 27.90batch/s]\u001b[A\n",
      "Epoch 0:  22%|██▏       | 166/740 [00:05<00:20, 27.92batch/s]\u001b[A\n",
      "Epoch 0:  23%|██▎       | 169/740 [00:06<00:20, 27.95batch/s]\u001b[A\n",
      "Epoch 0:  23%|██▎       | 172/740 [00:06<00:20, 27.97batch/s]\u001b[A\n",
      "Epoch 0:  24%|██▎       | 175/740 [00:06<00:20, 27.99batch/s]\u001b[A\n",
      "Epoch 0:  24%|██▍       | 178/740 [00:06<00:20, 28.02batch/s]\u001b[A\n",
      "Epoch 0:  24%|██▍       | 181/740 [00:06<00:19, 28.04batch/s]\u001b[A\n",
      "Epoch 0:  25%|██▍       | 184/740 [00:06<00:19, 28.06batch/s]\u001b[A\n",
      "Epoch 0:  25%|██▌       | 187/740 [00:06<00:19, 28.08batch/s]\u001b[A\n",
      "Epoch 0:  26%|██▌       | 190/740 [00:06<00:19, 28.10batch/s]\u001b[A\n",
      "Epoch 0:  26%|██▌       | 193/740 [00:06<00:19, 28.11batch/s]\u001b[A\n",
      "Epoch 0:  26%|██▋       | 196/740 [00:06<00:19, 28.13batch/s]\u001b[A\n",
      "Epoch 0:  27%|██▋       | 199/740 [00:07<00:19, 28.15batch/s]\u001b[A\n",
      "Epoch 0:  27%|██▋       | 202/740 [00:07<00:19, 28.17batch/s]\u001b[A\n",
      "Epoch 0:  28%|██▊       | 205/740 [00:07<00:18, 28.19batch/s]\u001b[A\n",
      "Epoch 0:  28%|██▊       | 208/740 [00:07<00:18, 28.20batch/s]\u001b[A\n",
      "Epoch 0:  29%|██▊       | 211/740 [00:07<00:18, 28.22batch/s]\u001b[A\n",
      "Epoch 0:  29%|██▉       | 214/740 [00:07<00:18, 28.23batch/s]\u001b[A\n",
      "Epoch 0:  29%|██▉       | 217/740 [00:07<00:18, 28.25batch/s]\u001b[A\n",
      "Epoch 0:  30%|██▉       | 220/740 [00:07<00:18, 28.26batch/s]\u001b[A\n",
      "Epoch 0:  30%|███       | 223/740 [00:07<00:18, 28.27batch/s]\u001b[A\n",
      "Epoch 0:  31%|███       | 226/740 [00:07<00:18, 28.28batch/s]\u001b[A\n",
      "Epoch 0:  31%|███       | 229/740 [00:08<00:18, 28.30batch/s]\u001b[A\n",
      "Epoch 0:  31%|███▏      | 232/740 [00:08<00:17, 28.31batch/s]\u001b[A\n",
      "Epoch 0:  32%|███▏      | 235/740 [00:08<00:17, 28.32batch/s]\u001b[A\n",
      "Epoch 0:  32%|███▏      | 238/740 [00:08<00:17, 28.34batch/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 241/740 [00:08<00:17, 28.35batch/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 244/740 [00:08<00:17, 28.36batch/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 247/740 [00:08<00:17, 28.37batch/s]\u001b[A\n",
      "Epoch 0:  34%|███▍      | 250/740 [00:08<00:17, 28.38batch/s]\u001b[A\n",
      "Epoch 0:  34%|███▍      | 253/740 [00:08<00:17, 28.39batch/s]\u001b[A\n",
      "Epoch 0:  35%|███▍      | 256/740 [00:09<00:17, 28.40batch/s]\u001b[A\n",
      "Epoch 0:  35%|███▌      | 259/740 [00:09<00:16, 28.41batch/s]\u001b[A\n",
      "Epoch 0:  35%|███▌      | 262/740 [00:09<00:16, 28.41batch/s]\u001b[A\n",
      "Epoch 0:  36%|███▌      | 265/740 [00:09<00:16, 28.42batch/s]\u001b[A\n",
      "Epoch 0:  36%|███▌      | 268/740 [00:09<00:16, 28.43batch/s]\u001b[A\n",
      "Epoch 0:  37%|███▋      | 271/740 [00:09<00:16, 28.44batch/s]\u001b[A\n",
      "Epoch 0:  37%|███▋      | 274/740 [00:09<00:16, 28.45batch/s]\u001b[A\n",
      "Epoch 0:  37%|███▋      | 277/740 [00:09<00:16, 28.46batch/s]\u001b[A\n",
      "Epoch 0:  38%|███▊      | 280/740 [00:09<00:16, 28.47batch/s]\u001b[A\n",
      "Epoch 0:  38%|███▊      | 283/740 [00:09<00:16, 28.47batch/s]\u001b[A\n",
      "Epoch 0:  39%|███▊      | 286/740 [00:10<00:15, 28.48batch/s]\u001b[A\n",
      "Epoch 0:  39%|███▉      | 289/740 [00:10<00:15, 28.49batch/s]\u001b[A\n",
      "Epoch 0:  39%|███▉      | 292/740 [00:10<00:15, 28.49batch/s]\u001b[A\n",
      "Epoch 0:  40%|███▉      | 295/740 [00:10<00:15, 28.50batch/s]\u001b[A\n",
      "Epoch 0:  40%|████      | 298/740 [00:10<00:15, 28.51batch/s]\u001b[A\n",
      "Epoch 0:  41%|████      | 301/740 [00:10<00:15, 28.51batch/s]\u001b[A\n",
      "Epoch 0:  41%|████      | 304/740 [00:10<00:15, 28.52batch/s]\u001b[A\n",
      "Epoch 0:  41%|████▏     | 307/740 [00:10<00:15, 28.53batch/s]\u001b[A\n",
      "Epoch 0:  42%|████▏     | 310/740 [00:10<00:15, 28.53batch/s]\u001b[A\n",
      "Epoch 0:  42%|████▏     | 313/740 [00:10<00:14, 28.54batch/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 316/740 [00:11<00:14, 28.55batch/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 319/740 [00:11<00:14, 28.55batch/s]\u001b[A\n",
      "Epoch 0:  44%|████▎     | 322/740 [00:11<00:14, 28.56batch/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 325/740 [00:11<00:14, 28.57batch/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 328/740 [00:11<00:14, 28.57batch/s]\u001b[A\n",
      "Epoch 0:  45%|████▍     | 331/740 [00:11<00:14, 28.58batch/s]\u001b[A\n",
      "Epoch 0:  45%|████▌     | 334/740 [00:11<00:14, 28.58batch/s]\u001b[A\n",
      "Epoch 0:  46%|████▌     | 337/740 [00:11<00:14, 28.59batch/s]\u001b[A\n",
      "Epoch 0:  46%|████▌     | 340/740 [00:11<00:13, 28.59batch/s]\u001b[A\n",
      "Epoch 0:  46%|████▋     | 343/740 [00:11<00:13, 28.60batch/s]\u001b[A\n",
      "Epoch 0:  47%|████▋     | 346/740 [00:12<00:13, 28.61batch/s]\u001b[A\n",
      "Epoch 0:  47%|████▋     | 349/740 [00:12<00:13, 28.61batch/s]\u001b[A\n",
      "Epoch 0:  48%|████▊     | 352/740 [00:12<00:13, 28.62batch/s]\u001b[A\n",
      "Epoch 0:  48%|████▊     | 355/740 [00:12<00:13, 28.62batch/s]\u001b[A\n",
      "Epoch 0:  48%|████▊     | 358/740 [00:12<00:13, 28.62batch/s]\u001b[A\n",
      "Epoch 0:  49%|████▉     | 361/740 [00:12<00:13, 28.63batch/s]\u001b[A\n",
      "Epoch 0:  49%|████▉     | 364/740 [00:12<00:13, 28.64batch/s]\u001b[A\n",
      "Epoch 0:  50%|████▉     | 367/740 [00:12<00:13, 28.64batch/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 370/740 [00:12<00:12, 28.65batch/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 373/740 [00:13<00:12, 28.65batch/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 376/740 [00:13<00:12, 28.66batch/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 379/740 [00:13<00:12, 28.66batch/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 382/740 [00:13<00:12, 28.66batch/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 385/740 [00:13<00:12, 28.66batch/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 388/740 [00:13<00:12, 28.67batch/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 391/740 [00:13<00:12, 28.68batch/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 394/740 [00:13<00:12, 28.68batch/s]\u001b[A\n",
      "Epoch 0:  54%|█████▎    | 397/740 [00:13<00:11, 28.68batch/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 400/740 [00:13<00:11, 28.69batch/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 403/740 [00:14<00:11, 28.69batch/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 406/740 [00:14<00:11, 28.70batch/s]\u001b[A\n",
      "Epoch 0:  55%|█████▌    | 409/740 [00:14<00:11, 28.70batch/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 412/740 [00:14<00:11, 28.70batch/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 415/740 [00:14<00:11, 28.71batch/s]\u001b[A\n",
      "Epoch 0:  56%|█████▋    | 418/740 [00:14<00:11, 28.71batch/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 421/740 [00:14<00:11, 28.72batch/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 424/740 [00:14<00:11, 28.72batch/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 427/740 [00:14<00:10, 28.72batch/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 430/740 [00:14<00:10, 28.72batch/s]\u001b[A\n",
      "Epoch 0:  59%|█████▊    | 433/740 [00:15<00:10, 28.73batch/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 436/740 [00:15<00:10, 28.73batch/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 439/740 [00:15<00:10, 28.74batch/s]\u001b[A\n",
      "Epoch 0:  60%|█████▉    | 442/740 [00:15<00:10, 28.74batch/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 445/740 [00:15<00:10, 28.74batch/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 448/740 [00:15<00:10, 28.75batch/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 451/740 [00:15<00:10, 28.75batch/s]\u001b[A\n",
      "Epoch 0:  61%|██████▏   | 454/740 [00:15<00:09, 28.75batch/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 457/740 [00:15<00:09, 28.76batch/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 460/740 [00:15<00:09, 28.76batch/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 463/740 [00:16<00:09, 28.76batch/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 466/740 [00:16<00:09, 28.77batch/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 469/740 [00:16<00:09, 28.77batch/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 472/740 [00:16<00:09, 28.77batch/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 475/740 [00:16<00:09, 28.77batch/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 478/740 [00:16<00:09, 28.78batch/s]\u001b[A\n",
      "Epoch 0:  65%|██████▌   | 481/740 [00:16<00:08, 28.78batch/s]\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "lengths array has to be sorted in decreasing order",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-84b6a741e1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoding_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data-science-playground/06 -CS3244 Project/Deep Reinforced Abstractive Summarisation/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, input_lengths)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack (back to padded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprev_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprev_l\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remember that new_length is the preceding length in the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lengths array has to be sorted in decreasing order\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: lengths array has to be sorted in decreasing order"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  65%|██████▌   | 481/740 [00:30<00:16, 15.77batch/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(NUM_EPOCHS):\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch_idx}', unit = \"batch\"):\n",
    "        stories,lengths = batch.story\n",
    "        summaries, _ = batch.summary\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*summaries.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            stories = stories.cuda()\n",
    "            summaries = summaries.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output,hidden = encoder(stories,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,summaries.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,summaries.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "        loss.backward()\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), f'{PATH}/model/encoder.model')\n",
    "torch.save(decoder.state_dict(), f'{PATH}/model/decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load(f'{PATH}/model/encoder.model'))\n",
    "decoder.load_state_dict(torch.load(f'{PATH}/model/encoder.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
