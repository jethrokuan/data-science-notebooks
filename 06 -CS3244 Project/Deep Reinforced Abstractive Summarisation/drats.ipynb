{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nltk\n",
    "import torchtext\n",
    "from torchtext.data import Example, Field, BucketIterator, TabularDataset, Iterator\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook, trange\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 31.4 GB  | Proc size: 161.5 MB\n",
      "GPU RAM Free: 12206MB | Used: 0MB | Util   0% | Total 12206MB\n",
      "Wed Mar 28 08:49:36 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   77C    P0    68W / 250W |      0MiB / 12206MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/diskA/jethro/cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid.feather',\n",
       " 'test.feather',\n",
       " 'train.pkl',\n",
       " 'raw',\n",
       " 'decoder.model',\n",
       " 'train.tsv',\n",
       " 'encoder.model',\n",
       " 'stories.feather',\n",
       " 'test.tsv',\n",
       " 'valid.tsv',\n",
       " 'train.feather']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=nltk.word_tokenize,use_vocab=True,lower=True, include_lengths=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(path=f'{PATH}/train.tsv',\n",
    "                            format='tsv',\n",
    "                            fields=[('input',TEXT), ('target',TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(path=f'{PATH}/test.tsv',\n",
    "                            format='tsv',\n",
    "                            fields=[('input',TEXT), ('target',TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = TabularDataset(path=f'{PATH}/valid.tsv',\n",
    "                           format='tsv',\n",
    "                           fields=[('input', TEXT), ('target', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 83092\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, test_data, valid_data, min_freq=2)\n",
    "\n",
    "tqdm.write(\"Vocabulary size: {}\".format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training stories: 73972\n",
      "Number of testing stories: 14794\n",
      "Number of validation stories: 3699\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_loader = BucketIterator(train_data,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "test_loader  = BucketIterator(test_data,batch_size=1, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "valid_loader = BucketIterator(valid_data,batch_size=1, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    " # May be slightly less due to skipping empty stories\n",
    "tqdm.write(\"Number of training stories: {}\".format(len(train_data)))\n",
    "tqdm.write(\"Number of testing stories: {}\".format(len(test_data)))\n",
    "tqdm.write(\"Number of validation stories: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = 100\n",
    "EMBED = 300\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(VOCAB_SIZE,EMBED,HIDDEN,bidirec=True)\n",
    "decoder = Decoder(VOCAB_SIZE,EMBED,HIDDEN*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    tqdm.write(\"Using CUDA\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using %d devices\" % (torch.cuda.device_count()))\n",
    "        encoder = nn.DataParallel(encoder)\n",
    "        decoder = nn.DataParallel(decoder)\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "decoder.embedding = encoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
    "enc_optim = optim.Adam(encoder.parameters(),lr=LR)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_MODEL_PATH = f'{PATH}/encoder.model'\n",
    "DECODER_MODEL_PATH = f'{PATH}/decoder.model'\n",
    "\n",
    "def load_models():\n",
    "    encoder.load_state_dict(torch.load(ENCODER_MODEL_PATH))\n",
    "    decoder.load_state_dict(torch.load(DECODER_MODEL_PATH))\n",
    "    \n",
    "def save_models():\n",
    "    torch.save(encoder.state_dict(), ENCODER_MODEL_PATH)\n",
    "    torch.save(decoder.state_dict(), DECODER_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    encoder = encoder.train()\n",
    "    decoder = decoder.train()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(train_loader, desc=\"Training Batches\"):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "        loss.backward()\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"Training: loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_loss(valid_loader):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(valid_loader, desc=\"Validation Batches\"):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"Validation: loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b7082c84404e35b66b0da04eea2c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac5ed115cb84a07b1d97422a63246ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=4624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  3.4017, loss variance:  0.0783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b9b892476543ef84e34e7a511043be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=3699), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  8.6416, loss variance:  7.0048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9438f567994c7d8755d114c5906c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=4624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  3.2993, loss variance:  0.0672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513dcbb35b7549fc81fa97dfc701f650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=3699), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  8.7326, loss variance:  7.4038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3719055d7f49b1911b88c53f79e669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=4624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7db8e29c68b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcalculate_validation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-d2fa90811b1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoding_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data-science-playground/06 -CS3244 Project/Deep Reinforced Abstractive Summarisation/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, max_length, encoder_outputs, encoder_lengths)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# Intra Temporal Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mcontext_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mcontext_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data-science-playground/06 -CS3244 Project/Deep Reinforced Abstractive Summarisation/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, encoder_outputs, encoder_lengths, return_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_context_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_unmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data-science-playground/06 -CS3244 Project/Deep Reinforced Abstractive Summarisation/attention.py\u001b[0m in \u001b[0;36mfill_context_mask\u001b[0;34m(self, mask, sizes, v_mask, v_unmask)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_unmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mn_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "for epoch_idx in tnrange(NUM_EPOCHS, desc=\"Epochs\", unit=\"epoch\"):\n",
    "    train(train_loader)\n",
    "    calculate_validation_loss(valid_loader)\n",
    "    save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import ROUGE\n",
    "from __future__ import print_function\n",
    "rouge = ROUGE()\n",
    "\n",
    "def get_string(summary):\n",
    "    result = \"\"\n",
    "    for idx in summary:\n",
    "        if idx in [0, 1]: # <unk> and <pad>\n",
    "            continue\n",
    "        if idx < len(TEXT.vocab.itos):\n",
    "            result += (TEXT.vocab.itos[idx] + \" \")\n",
    "    return result\n",
    "\n",
    "def show_selection_of_output(encoder, decoder, loader, num_to_show = 5, num_to_calculate = 100):\n",
    "    total_rouge_score = {\"rouge-1\": {\"recall\": 0.0, \"precision\": 0.0},\n",
    "                         \"rouge-2\": {\"recall\": 0.0, \"precision\": 0.0}}\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i == num_to_calculate:\n",
    "            break\n",
    "        inputs, lengths = batch.input\n",
    "        targets, _ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        reference_article = inputs.data.cpu().numpy()[0]\n",
    "        reference_summary = targets.data.cpu().numpy()[0]\n",
    "        generated_summary = [np.argmax(word) for word in score.data.cpu().numpy()[0]]\n",
    "\n",
    "        reference_article = get_string(reference_article)\n",
    "        reference = get_string(reference_summary)\n",
    "        generated = get_string(generated_summary)\n",
    "\n",
    "        rouge_score = rouge.score(reference, generated)\n",
    "        \n",
    "        total_rouge_score[\"rouge-1\"][\"recall\"] += rouge_score[\"rouge-1\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-1\"][\"precision\"] += rouge_score[\"rouge-1\"][\"precision\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"recall\"] += rouge_score[\"rouge-2\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"precision\"] += rouge_score[\"rouge-2\"][\"precision\"]\n",
    "\n",
    "        if i < num_to_show:\n",
    "            print(\"\\nReference article:\\n{}\".format(reference_article))\n",
    "            print(\"\\nReference summary:\\n{}\".format(reference))\n",
    "            print(\"\\nGenerated summary:\\n{}\".format(generated))\n",
    "            print(\"\\nROUGE score: {}\\n\".format(rouge_score))\n",
    "        \n",
    "    total_rouge_score[\"rouge-1\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-1\"][\"precision\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"precision\"] /= num_to_show\n",
    "    print(\"Mean ROUGE score: {}\\n\".format(total_rouge_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference article:\n",
      "`` cairo seven coptic egyptians living abroad were sentenced to death wednesday by a court in cairo for their connection to an inflammatory anti-islam film , the prosecutor 's office said . the suspects are accused of being involved with the production of the film in california , said adel al saeed , official spokesman for the prosecutor 's office . since the egyptian citizens were tried in absentia , the sentence would be applied only if they returned to egypt . protests against the `` '' innocence of muslims `` '' film erupted in september in many muslim countries , including egypt '' \n",
      "\n",
      "Reference summary:\n",
      "prosecutor : 7 coptic egyptians are sentenced to death over involvement in an anti-islam film \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.0, 'precision': 0.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference article:\n",
      "washington the wall street journal reported friday that office rents in washington are poised to overtake rents in new york city . washington now boasts the lowest office vacancy rate in the nation . new york city is bleeding jobs , unemployment is over 10 percent . washington is booming as government agencies like tarp and the general services administration expand . new york 's crisis and washington 's growth is more than a business page story . over two centuries , american culture has been shaped by the physical separation of politics and finance . the british might \n",
      "\n",
      "Reference summary:\n",
      "rents for offices in washington could soon be more expensive than in new york \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.0, 'precision': 0.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference article:\n",
      "`` cnn unless you 've been stuck in a mine shaft or visiting a distant planet for the past few decades , chances are you 've heard of bob marley and usain bolt and can identify both as the most famous sons of jamaican soil . beyond reggae and track icons , however , there are many fascinating things less widely known about `` '' `` '' that make this island of just 3 million people stand out . here are eight things to know for starters : james bond 's birthplace ian fleming conjured up and penned the thrilling international spy '' \n",
      "\n",
      "Reference summary:\n",
      "ian fleming created james bond in jamaica \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.0, 'precision': 0.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference article:\n",
      "`` new york while president obama takes plenty of heat over his plans to overhaul domestic policies , critics have also taken aim at his foreign policy approach , particularly as it relates to human rights around the globe . human rights watch advocacy director tom malinowski says obama should have met with the dalai lama . human rights watch advocacy director tom malinowski said wednesday that while the administration appeared to have `` '' gotten the balance right `` '' on myanmar , the military asian nation formerly known as burma , by starting a dialogue while maintaining sanctions , `` '' '' \n",
      "\n",
      "Reference summary:\n",
      "good start in myanmar , china problematic , says human rights watch official \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.0, 'precision': 0.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference article:\n",
      "amid all the talk of germany 's new-found domination of european football after the success of bayern munich and borussia dortmund in reaching the champions league final , juventus ' achievement of winning the italian title for a record-extending 29th time almost passed by without notice at the weekend . it was juve 's second consecutive serie a crown and provided further testimony to the impact coach antonio conte has had given he has only been in charge since mid-2011 . like all successful coaches , conte has already turned his thoughts to the future rather than the past as \n",
      "\n",
      "Reference summary:\n",
      "juventus secure second successive serie a title with 1-0 win over palermo \n",
      "\n",
      "Generated summary:\n",
      "\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.0, 'precision': 0.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "Mean ROUGE score: {'rouge-1': {'recall': 0.0, 'precision': 0.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_selection_of_output(encoder, decoder, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
