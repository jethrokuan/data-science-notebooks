{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nltk\n",
    "import torchtext\n",
    "from torchtext.data import Example, Field, BucketIterator, TabularDataset, Iterator\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook, trange\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 30.5 GB  | Proc size: 161.5 MB\n",
      "GPU RAM Free: 12206MB | Used: 0MB | Util   0% | Total 12206MB\n",
      "Thu Mar 29 14:43:06 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   66C    P0    63W / 250W |      0MiB / 12206MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/diskA/jethro/cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_small.tsv',\n",
       " 'valid.feather',\n",
       " 'test.feather',\n",
       " 'test_small.tsv',\n",
       " 'encoder_small.model',\n",
       " 'train.pkl',\n",
       " 'valid_small.tsv',\n",
       " 'raw',\n",
       " 'decoder.model',\n",
       " 'train.tsv',\n",
       " 'encoder.model',\n",
       " 'decoder_small.model',\n",
       " 'stories.feather',\n",
       " 'test.tsv',\n",
       " 'valid.tsv',\n",
       " 'train.feather']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize = nltk.word_tokenize, use_vocab = True, init_token = \"<s>\", eos_token = \"<e>\", lower = True, include_lengths = True, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "USE_SMALL_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALL_DATASET:\n",
    "    train_ds, test_ds, valid_ds = f'{PATH}/train_small.tsv', f'{PATH}/test_small.tsv', f'{PATH}/valid_small.tsv'\n",
    "else:\n",
    "    train_ds, test_ds, valid_ds = f'{PATH}/train.tsv', f'{PATH}/test.tsv', f'{PATH}/valid.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(path=train_ds,\n",
    "                            format='tsv',\n",
    "                            fields=[('input',TEXT), ('target',TEXT)])\n",
    "test_data = TabularDataset(path=test_ds,\n",
    "                            format='tsv',\n",
    "                            fields=[('input',TEXT), ('target',TEXT)])\n",
    "valid_data = TabularDataset(path=valid_ds,\n",
    "                           format='tsv',\n",
    "                           fields=[('input', TEXT), ('target', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19194\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, test_data, valid_data, min_freq=2)\n",
    "\n",
    "tqdm.write(\"Vocabulary size: {}\".format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training stories: 3000\n",
      "Number of testing stories: 1000\n",
      "Number of validation stories: 1000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_loader = BucketIterator(train_data,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "test_loader  = BucketIterator(test_data,batch_size=1, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "valid_loader = BucketIterator(valid_data,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    " # May be slightly less due to skipping empty stories\n",
    "tqdm.write(\"Number of training stories: {}\".format(len(train_data)))\n",
    "tqdm.write(\"Number of testing stories: {}\".format(len(test_data)))\n",
    "tqdm.write(\"Number of validation stories: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "EMBED = 300\n",
    "\n",
    "if USE_SMALL_DATASET:\n",
    "    HIDDEN = 50\n",
    "else:\n",
    "    HIDDEN = 200\n",
    "    \n",
    "    \n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "LR = 1e-4\n",
    "\n",
    "encoder = Encoder(VOCAB_SIZE,EMBED,HIDDEN,bidirec=True)\n",
    "decoder = Decoder(VOCAB_SIZE,EMBED,HIDDEN*2)\n",
    "\n",
    "if USE_CUDA:\n",
    "    tqdm.write(\"Using CUDA\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using %d devices\" % (torch.cuda.device_count()))\n",
    "        encoder = nn.DataParallel(encoder)\n",
    "        decoder = nn.DataParallel(decoder)\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "decoder.embedding = encoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (embedding): Embedding(19194, 300)\n",
       "  (lstm): LSTM(300, 50, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(19194, 300)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (lstm): LSTM(300, 100, batch_first=True)\n",
       "  (linear): Linear(in_features=300, out_features=19194)\n",
       "  (dec_attention): Attention(\n",
       "    (attn): Linear(in_features=100, out_features=100)\n",
       "  )\n",
       "  (enc_attention): IntraTempAttention(\n",
       "    (attn): Linear(in_features=100, out_features=100)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
    "enc_optim = optim.Adam(encoder.parameters(),lr=LR)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALL_DATASET:\n",
    "    APPEND = \"_small\"\n",
    "else:\n",
    "    APPEND = \"\"\n",
    "ENCODER_MODEL_PATH = f'{PATH}/encoder{APPEND}.model'\n",
    "DECODER_MODEL_PATH = f'{PATH}/decoder{APPEND}.model'\n",
    "\n",
    "def load_models():\n",
    "    encoder.load_state_dict(torch.load(ENCODER_MODEL_PATH))\n",
    "    decoder.load_state_dict(torch.load(DECODER_MODEL_PATH))\n",
    "    \n",
    "def save_models():\n",
    "    torch.save(encoder.state_dict(), ENCODER_MODEL_PATH)\n",
    "    torch.save(decoder.state_dict(), DECODER_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    encoder = encoder.train()\n",
    "    decoder = decoder.train()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(train_loader, desc=\"Training Batches\", leave=False):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "        loss.backward()\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"Training: loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))\n",
    "    return loss_mean, loss_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_loss(valid_loader):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(valid_loader, desc=\"Validation Batches\", leave=False):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"Validation: loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))\n",
    "    return loss_mean, loss_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tensorboard(writer, epoch, train_loss, valid_loss):\n",
    "     writer.add_scalars('data/loss',\n",
    "                        {'train': train_loss,\n",
    "                         'valid': valid_loss},\n",
    "                        epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccaa14b7f91749d7802335198451f29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e083de5256dd4cdb9e865d319e79a5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.5954, loss variance:  0.0443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca610501a571423ba2eda6815adc9b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  6.9516, loss variance:  0.0343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a0a23365f44c8e8ed9f683f6b30c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.4528, loss variance:  0.0412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5fc49dc2c34dbfa1c396ffd4332d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0170, loss variance:  0.0709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09ea32e3234478b9ec179aa5be1c94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.3918, loss variance:  0.0414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb6ea3c9ad44bf09f62f0739ff93cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0239, loss variance:  0.0780\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfef64d49ef4bb0a65252dfeab69af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.3470, loss variance:  0.0459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78786ea68594f82a879114ace3d4c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0344, loss variance:  0.0698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68238170cb94e5bab73d7f984b45cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.3046, loss variance:  0.0427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616a4b4247c049259c223dfdde4a2f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0658, loss variance:  0.0535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f633a4f6b4048488c4bdaf934b07141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.2687, loss variance:  0.0483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd0c11f1c4d4cb39f0540bc70ca6fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.1013, loss variance:  0.0630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1da72dcc224758b505c209ef43ee5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.2345, loss variance:  0.0494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df5e0cd49154228aed2a0fd744d6de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.1272, loss variance:  0.0837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8dc2d730124f8dbcf562d1bb0a8818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.2044, loss variance:  0.0455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce0c6afb9394201906821d147e9cb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.1633, loss variance:  0.0709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bae73412f24850b91851b63af3dbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-955faa11f154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_validation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwrite_to_tensorboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-732977922044>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtotal_squared_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0menc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdec_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1000\n",
    "for epoch_idx in tnrange(NUM_EPOCHS, desc=\"Epochs\", unit=\"epoch\"):\n",
    "    train_loss, train_variance = train(train_loader)\n",
    "    valid_loss, valid_variance = calculate_validation_loss(valid_loader)\n",
    "    write_to_tensorboard(writer, epoch_idx, train_loss, valid_loss)\n",
    "    save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import ROUGE\n",
    "from __future__ import print_function\n",
    "rouge = ROUGE()\n",
    "\n",
    "def get_string(summary):\n",
    "    result = \" \".join([TEXT.vocab.itos[idx] for idx in summary])\n",
    "    return result\n",
    "\n",
    "def show_selection_of_output(loader, num_to_show, num_to_calculate):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    total_rouge_score = {\"rouge-1\": {\"recall\": 0.0, \"precision\": 0.0},\n",
    "                         \"rouge-2\": {\"recall\": 0.0, \"precision\": 0.0}}\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i == num_to_calculate:\n",
    "            break\n",
    "        inputs, lengths = batch.input\n",
    "        targets, _ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start, hidden, targets.size(1), output, lengths)\n",
    "\n",
    "        reference_summary = targets.data.cpu().numpy()[0]\n",
    "        generated_summary = [np.argmax(word) for word in score.data.cpu().numpy()]\n",
    "\n",
    "        reference = get_string(reference_summary)\n",
    "        generated = get_string(generated_summary)\n",
    "\n",
    "        rouge_score = rouge.score(reference, generated)\n",
    "        \n",
    "        total_rouge_score[\"rouge-1\"][\"recall\"] += rouge_score[\"rouge-1\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-1\"][\"precision\"] += rouge_score[\"rouge-1\"][\"precision\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"recall\"] += rouge_score[\"rouge-2\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"precision\"] += rouge_score[\"rouge-2\"][\"precision\"]\n",
    "\n",
    "        if i < num_to_show:\n",
    "            print(\"\\nReference summary:\\n{}\".format(reference))\n",
    "            print(\"\\nGenerated summary:\\n{}\".format(generated))\n",
    "            print(\"\\nROUGE score: {}\\n\".format(rouge_score))\n",
    "        \n",
    "    total_rouge_score[\"rouge-1\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-1\"][\"precision\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"precision\"] /= num_to_show\n",
    "    print(\"Mean ROUGE score: {}\\n\".format(total_rouge_score))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference summary:\n",
      "<s> romney and perry entered as frontrunners and left as frontrunners , said david gergen <e> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.07692307692307693, 'precision': 1.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> eric liu : my longtime partner , , and i finally got married before labor day <e> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.08695652173913043, 'precision': 1.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> ethiopia is building the largest <unk> dam in africa <e> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.11764705882352941, 'precision': 1.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> in miami , 32 people -- including two doctors and eight nurses -- were charged <e> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.08695652173913043, 'precision': 1.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> new report on affect of 2008 sichuan earthquake on wild giant panda population <e> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <s> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.09090909090909091, 'precision': 1.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "Mean ROUGE score: {'rouge-1': {'recall': 0.09187845402679162, 'precision': 1.0}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_selection_of_output(train_loader, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: <s> port-au-prince , haiti in january 2010 a <unk> magnitude earthquake rocked haiti , killing more than 250,000 people and damaging its infrastructure , including some water systems . even before the quake , haiti 's water systems were fragile , and just months after the quake the country was hit with a devastating cholera outbreak -- the first in nearly a century . by the time the outbreak subsided , more than 8,000 people had died and hundreds of thousands more had become sick . independent studies suggest the outbreak was caused by u.n. peacekeepers who improperly disposed of <unk> <e>\n",
      "Target summary: <s> haiti still recovering from cholera epidemic that left 8,000 dead <e>\n",
      "Best sequence: <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
      "Top candidates:\n",
      "\t<s> new <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
      "\t<s> `` <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
      "\t<s> the <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
      "\t<s> <s> new <s> <s> <s> <s> <s> <s> <s> <s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from beam import BeamSearch\n",
    "beam_search = BeamSearch()\n",
    "\n",
    "BEAM_WIDTH  = 5\n",
    "BEAM_DEPTH  = 10\n",
    "NUM_TO_SHOW = 3\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i == NUM_TO_SHOW:\n",
    "        break\n",
    "    inputs, lengths = batch.input\n",
    "    targets, _ = batch.target\n",
    "    if USE_CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "    outputs, hidden = encoder(inputs, lengths.tolist())\n",
    "    cell = decoder.init_context(inputs.size(0))\n",
    "    \n",
    "    best_sequence, top_candidates = beam_search.get_words(hidden, cell, TEXT.vocab.stoi[\"<s>\"], outputs, lengths, decoder, TEXT.vocab, BEAM_WIDTH, BEAM_DEPTH)\n",
    "    \n",
    "    \n",
    "    target_summary = get_string(targets.data.cpu().numpy()[0])\n",
    "        \n",
    "    print(\"Article: {}\".format(\" \".join([TEXT.vocab.itos[idx] for idx in inputs.cpu().data[0]])))\n",
    "    print(\"Target summary: {}\".format(target_summary))\n",
    "    print(\"Best sequence: {}\".format(\" \".join(best_sequence)))\n",
    "    print(\"Top candidates:\")\n",
    "    for candidate in top_candidates[1:]:\n",
    "        print(\"\\t{}\".format(\" \".join(candidate)))\n",
    "    print(\"\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
