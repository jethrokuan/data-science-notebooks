{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nltk\n",
    "import torchtext\n",
    "from torchtext.data import Example, Field, BucketIterator, TabularDataset, Iterator\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook, trange\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 31.5 GB  | Proc size: 163.9 MB\n",
      "GPU RAM Free: 12206MB | Used: 0MB | Util   0% | Total 12206MB\n",
      "Sun Apr  1 13:15:48 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   41C    P0    58W / 250W |      0MiB / 12206MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/diskA/jethro/cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_small.tsv',\n",
       " 'valid.feather',\n",
       " 'test.feather',\n",
       " 'test_small.tsv',\n",
       " 'encoder_small.model',\n",
       " 'train.pkl',\n",
       " 'valid_small.tsv',\n",
       " 'raw',\n",
       " 'decoder.model',\n",
       " 'train.tsv',\n",
       " 'encoder.model',\n",
       " 'decoder_small.model',\n",
       " 'stories.feather',\n",
       " 'test.tsv',\n",
       " 'valid.tsv',\n",
       " 'train.feather']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=nltk.word_tokenize, use_vocab = True, init_token = \"<s>\", eos_token = \"<e>\", lower = True, include_lengths = True, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "USE_SMALL_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALL_DATASET:\n",
    "    train_ds, test_ds, valid_ds = f'{PATH}/train_small.tsv', f'{PATH}/test_small.tsv', f'{PATH}/valid_small.tsv'\n",
    "else:\n",
    "    train_ds, test_ds, valid_ds = f'{PATH}/train.tsv', f'{PATH}/test.tsv', f'{PATH}/valid.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(path=train_ds,\n",
    "                            format='tsv',\n",
    "                            fields=[('input',TEXT), ('target',TEXT)])\n",
    "test_data = TabularDataset(path=test_ds,\n",
    "                            format='tsv',\n",
    "                            fields=[('input',TEXT), ('target',TEXT)])\n",
    "valid_data = TabularDataset(path=valid_ds,\n",
    "                           format='tsv',\n",
    "                           fields=[('input', TEXT), ('target', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14453\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, test_data, valid_data, min_freq=2)\n",
    "\n",
    "tqdm.write(\"Vocabulary size: {}\".format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training stories: 3000\n",
      "Number of testing stories: 1000\n",
      "Number of validation stories: 1000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_loader = BucketIterator(train_data,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "test_loader  = BucketIterator(test_data,batch_size=1, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    "valid_loader = BucketIterator(valid_data,batch_size=BATCH_SIZE, device=None,\n",
    "                              sort_key=lambda x: len(x.input),sort_within_batch=True,\n",
    "                              repeat=False,shuffle=True)\n",
    " # May be slightly less due to skipping empty stories\n",
    "tqdm.write(\"Number of training stories: {}\".format(len(train_data)))\n",
    "tqdm.write(\"Number of testing stories: {}\".format(len(test_data)))\n",
    "tqdm.write(\"Number of validation stories: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "EMBED = 300\n",
    "\n",
    "if USE_SMALL_DATASET:\n",
    "    HIDDEN = 50\n",
    "else:\n",
    "    HIDDEN = 200\n",
    "    \n",
    "    \n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "LR = 1e-4\n",
    "\n",
    "encoder = Encoder(VOCAB_SIZE,EMBED,HIDDEN,bidirec=True)\n",
    "decoder = Decoder(VOCAB_SIZE,EMBED,HIDDEN*2)\n",
    "\n",
    "if USE_CUDA:\n",
    "    tqdm.write(\"Using CUDA\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using %d devices\" % (torch.cuda.device_count()))\n",
    "        encoder = nn.DataParallel(encoder)\n",
    "        decoder = nn.DataParallel(decoder)\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "decoder.embedding = encoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (embedding): Embedding(14453, 300)\n",
       "  (lstm): LSTM(300, 50, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(14453, 300)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (lstm): LSTM(300, 100, batch_first=True)\n",
       "  (linear): Linear(in_features=300, out_features=14453)\n",
       "  (dec_attention): Attention(\n",
       "    (attn): Linear(in_features=100, out_features=100)\n",
       "  )\n",
       "  (enc_attention): IntraTempAttention(\n",
       "    (attn): Linear(in_features=100, out_features=100)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
    "enc_optim = optim.Adam(encoder.parameters(),lr=LR)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALL_DATASET:\n",
    "    APPEND = \"_small\"\n",
    "else:\n",
    "    APPEND = \"\"\n",
    "ENCODER_MODEL_PATH = f'{PATH}/encoder{APPEND}.model'\n",
    "DECODER_MODEL_PATH = f'{PATH}/decoder{APPEND}.model'\n",
    "\n",
    "def load_models():\n",
    "    encoder.load_state_dict(torch.load(ENCODER_MODEL_PATH))\n",
    "    decoder.load_state_dict(torch.load(DECODER_MODEL_PATH))\n",
    "    \n",
    "def save_models():\n",
    "    torch.save(encoder.state_dict(), ENCODER_MODEL_PATH)\n",
    "    torch.save(decoder.state_dict(), DECODER_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    encoder = encoder.train()\n",
    "    decoder = decoder.train()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(train_loader, desc=\"Training Batches\", leave=False):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "        loss.backward()\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"Training: loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))\n",
    "    return loss_mean, loss_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_loss(valid_loader):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    total_loss, total_squared_loss, num_batches = 0.0, 0.0, 0\n",
    "    for batch in tqdm_notebook(valid_loader, desc=\"Validation Batches\", leave=False):\n",
    "        inputs,lengths = batch.input\n",
    "        targets,_ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start,hidden,targets.size(1),output,lengths)\n",
    "\n",
    "        loss = loss_function(score,targets.view(-1))\n",
    "        total_loss += loss.data[0]\n",
    "        total_squared_loss += loss.data[0]**2\n",
    "        num_batches += 1\n",
    "    loss_mean = total_loss / num_batches\n",
    "    loss_variance = (total_squared_loss - (total_loss**2 / num_batches)) / (num_batches - 1)\n",
    "    tqdm.write(\"Validation: loss mean: %7.4f, loss variance: %7.4f\" % (loss_mean, loss_variance))\n",
    "    return loss_mean, loss_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tensorboard(writer, epoch, train_loss, valid_loss):\n",
    "     writer.add_scalars('data/loss',\n",
    "                        {'train': train_loss,\n",
    "                         'valid': valid_loss},\n",
    "                        epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccaa14b7f91749d7802335198451f29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e083de5256dd4cdb9e865d319e79a5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.5954, loss variance:  0.0443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca610501a571423ba2eda6815adc9b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  6.9516, loss variance:  0.0343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a0a23365f44c8e8ed9f683f6b30c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.4528, loss variance:  0.0412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5fc49dc2c34dbfa1c396ffd4332d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0170, loss variance:  0.0709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09ea32e3234478b9ec179aa5be1c94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.3918, loss variance:  0.0414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb6ea3c9ad44bf09f62f0739ff93cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0239, loss variance:  0.0780\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfef64d49ef4bb0a65252dfeab69af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.3470, loss variance:  0.0459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78786ea68594f82a879114ace3d4c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0344, loss variance:  0.0698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68238170cb94e5bab73d7f984b45cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.3046, loss variance:  0.0427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616a4b4247c049259c223dfdde4a2f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.0658, loss variance:  0.0535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f633a4f6b4048488c4bdaf934b07141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.2687, loss variance:  0.0483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd0c11f1c4d4cb39f0540bc70ca6fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.1013, loss variance:  0.0630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1da72dcc224758b505c209ef43ee5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.2345, loss variance:  0.0494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df5e0cd49154228aed2a0fd744d6de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.1272, loss variance:  0.0837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8dc2d730124f8dbcf562d1bb0a8818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss mean:  6.2044, loss variance:  0.0455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce0c6afb9394201906821d147e9cb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation Batches', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss mean:  7.1633, loss variance:  0.0709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bae73412f24850b91851b63af3dbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Batches', max=188), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-955faa11f154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_validation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwrite_to_tensorboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-732977922044>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtotal_squared_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0menc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdec_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/urop/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1000\n",
    "for epoch_idx in tnrange(NUM_EPOCHS, desc=\"Epochs\", unit=\"epoch\"):\n",
    "    train_loss, train_variance = train(train_loader)\n",
    "    valid_loss, valid_variance = calculate_validation_loss(valid_loader)\n",
    "    write_to_tensorboard(writer, epoch_idx, train_loss, valid_loss)\n",
    "    save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import ROUGE\n",
    "from __future__ import print_function\n",
    "rouge = ROUGE()\n",
    "\n",
    "def get_string(summary):\n",
    "    result = \" \".join([TEXT.vocab.itos[idx] for idx in summary])\n",
    "    return result\n",
    "\n",
    "def show_selection_of_output(loader, num_to_show, num_to_calculate):\n",
    "    global encoder\n",
    "    global decoder\n",
    "    total_rouge_score = {\"rouge-1\": {\"recall\": 0.0, \"precision\": 0.0},\n",
    "                         \"rouge-2\": {\"recall\": 0.0, \"precision\": 0.0}}\n",
    "    encoder = encoder.eval()\n",
    "    decoder = decoder.eval()\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i == num_to_calculate:\n",
    "            break\n",
    "        inputs, lengths = batch.input\n",
    "        targets, _ = batch.target\n",
    "        decoding_start = Variable(torch.LongTensor([TEXT.vocab.stoi['<s>']]*targets.size(0))).unsqueeze(1)\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            decoding_start = decoding_start.cuda()\n",
    "\n",
    "        output,hidden = encoder(inputs,lengths.tolist())\n",
    "        score = decoder(decoding_start, hidden, targets.size(1), output, lengths)\n",
    "\n",
    "        reference_summary = targets.data.cpu().numpy()[0]\n",
    "        generated_summary = [np.argmax(word) for word in score.data.cpu().numpy()]\n",
    "\n",
    "        reference = get_string(reference_summary)\n",
    "        generated = get_string(generated_summary)\n",
    "\n",
    "        rouge_score = rouge.score(reference, generated)\n",
    "        \n",
    "        total_rouge_score[\"rouge-1\"][\"recall\"] += rouge_score[\"rouge-1\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-1\"][\"precision\"] += rouge_score[\"rouge-1\"][\"precision\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"recall\"] += rouge_score[\"rouge-2\"][\"recall\"]\n",
    "        total_rouge_score[\"rouge-2\"][\"precision\"] += rouge_score[\"rouge-2\"][\"precision\"]\n",
    "\n",
    "        if i < num_to_show:\n",
    "            print(\"\\nReference summary:\\n{}\".format(reference))\n",
    "            print(\"\\nGenerated summary:\\n{}\".format(generated))\n",
    "            print(\"\\nROUGE score: {}\\n\".format(rouge_score))\n",
    "        \n",
    "    total_rouge_score[\"rouge-1\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-1\"][\"precision\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"recall\"] /= num_to_show\n",
    "    total_rouge_score[\"rouge-2\"][\"precision\"] /= num_to_show\n",
    "    print(\"Mean ROUGE score: {}\\n\".format(total_rouge_score))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference summary:\n",
      "<s> kelli abad disappeared the night that she and her husband argued , he says <e> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> the the , , , , , , , , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the 's says the to in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : a , , a , , , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the least says , , , , , , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the united has in in in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the says says the in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the 's says the to the the , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the says says , , , , , , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> u.s. says says says says in in , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the obama : to to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the u.s. says the to in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> a <unk> : a to in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> police 's , to to to to in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> `` 's , `` `` `` `` `` `` `` `` `` `` <e> <e> <e> <e> <e> <e> <e> <e> <s> the u.s. says the to in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.22727272727272727, 'precision': 0.7642045454545454}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> john terry scores winning goal for chelsea in a 2-1 win at burnley <e> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> valentino terry wins the to in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the obama , , , , , , , , , , <e> <e> <e> <e> <e> <s> <unk> : to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> f/a defended wins to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the robinson 's the the the the the the <e> <e> <e> <e> <e> <e> <e> <e> <s> the says says says says , , , , <e> <e> <e> <e> <e> <e> <e> <e> <s> a <unk> <unk> to to in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> police 's , to to in in , <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : the <unk> the the <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <s> police 's says to , , , , , <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> of the in in in in in <e> <e> <e> <e> <e> <e> <e> <e> <s> `` 's `` `` `` `` `` `` `` `` `` `` `` `` <e> <e> <e> <s> manchester has wins to in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the least , a a , a , a , , <e> <e> <e> <e> <e> <e> <s> <unk> <unk> : to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : the <unk> <unk> the <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.2777777777777778, 'precision': 0.5590277777777778}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> latest china corruption scandal : $ <unk> billion seized from people around <unk> chief zhou yongkang <e> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> the <unk> <unk> <unk> the in <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : a , , to , , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : the <unk> the the <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the the says the the the the , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> a <unk> : to to to to in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> : : <unk> to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> 's <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the says says says in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> <unk> <unk> <unk> to to <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the united of the in in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> `` `` : `` `` `` `` `` `` `` `` `` `` `` <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> <unk> : to , , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.20833333333333334, 'precision': 0.7265625}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> germany 's industry is among the most successful in europe <e> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> the <unk> : the the the the <unk> the <unk> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <s> the 's , , , , , , , , , <e> <e> <e> <e> <e> <s> <unk> <unk> wins to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the founder marking <unk> to to to to <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> <unk> : to , to , , <e> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <s> aleksandr these : to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <s> <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <s> ac 's , to to to to , <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <s> <unk> <unk> : <unk> <unk> to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> tickets : : <unk> <unk> to to to <e> <e> <e> <e> <e> <e> <e> <e> <s> a obama , to to to to , , <e> <e> <e> <e> <e> <e> <e> <s> a : : to to to to to , , <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.23529411764705882, 'precision': 0.5110294117647058}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "\n",
      "Reference summary:\n",
      "<s> bill to introduce carbon tax on country 's biggest <unk> passed by australian senate <e> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "Generated summary:\n",
      "<s> obama 's of to to to to in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> <unk> <unk> <unk> in in <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : to to to to , , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> <unk> : a <unk> of of <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the 's , to to in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the says says the , , the , , <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> obama obama , to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> : the <unk> of of <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> <unk> : : <unk> to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> <unk> the the the the <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` `` <s> <unk> <unk> : <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> u.s. federer to to to to to to <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the <unk> of the in in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the of says in in in in in in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <s> the of <unk> <unk> <unk> in in <unk> in <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e> <e>\n",
      "\n",
      "ROUGE score: {'rouge-1': {'recall': 0.22727272727272727, 'precision': 0.7471590909090909}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n",
      "Mean ROUGE score: {'rouge-1': {'recall': 0.2351901366607249, 'precision': 0.661596665181224}, 'rouge-2': {'recall': 0.0, 'precision': 0.0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_selection_of_output(train_loader, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: <s> the taliban have been forced out of power , osama bin laden is dead , and al qaeda , by many accounts , is not nearly as powerful as it once was . but 10 years after the start of the war in afghanistan , many issues still plague the country . <e>\n",
      "Target summary: <s> it has been 10 years since the start of the war in afghanistan <e>\n",
      "Best sequence: <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
      "Top candidates:\n",
      "\t<s> <s> <s> <s> <s> <s> <s> <s> <s> <unk> <s>\n",
      "\t<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <unk>\n",
      "\t<s> <s> <s> <s> <s> <s> <s> <s> <unk> <s> <s>\n",
      "\t<s> <s> <s> <s> <s> <s> <s> <s> <s> the <s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from beam import BeamSearch\n",
    "beam_search = BeamSearch()\n",
    "\n",
    "BEAM_WIDTH  = 5\n",
    "BEAM_DEPTH  = 10\n",
    "NUM_TO_SHOW = 3\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i == NUM_TO_SHOW:\n",
    "        break\n",
    "    inputs, lengths = batch.input\n",
    "    targets, _ = batch.target\n",
    "    if USE_CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "    outputs, hidden = encoder(inputs, lengths.tolist())\n",
    "    cell = decoder.init_context(inputs.size(0))\n",
    "    \n",
    "    best_sequence, top_candidates = beam_search.get_words(hidden, cell, TEXT.vocab.stoi[\"<s>\"], outputs, lengths, decoder, TEXT.vocab, BEAM_WIDTH, BEAM_DEPTH)\n",
    "    \n",
    "    \n",
    "    target_summary = get_string(targets.data.cpu().numpy()[0])\n",
    "        \n",
    "    print(\"Article: {}\".format(\" \".join([TEXT.vocab.itos[idx] for idx in inputs.cpu().data[0]])))\n",
    "    print(\"Target summary: {}\".format(target_summary))\n",
    "    print(\"Best sequence: {}\".format(\" \".join(best_sequence)))\n",
    "    print(\"Top candidates:\")\n",
    "    for candidate in top_candidates[1:]:\n",
    "        print(\"\\t{}\".format(\" \".join(candidate)))\n",
    "    print(\"\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
